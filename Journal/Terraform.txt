							TERRAFORM



							Introduction

- The go to software for IAC. Allows you to deploy infrastructure on AWS using Code. 

- IAC Benefits: Easy to adjust, Easy to replicate, Easy to scale, Easier to see in it's totality. 

- Terraform is a Infrastructure Orchestration tool. Ansible is a config management tool. 

- Terraform is a cloud Agnostic too. It can deploy infrastructure to: AWS, Azure and Google Cloud Platform.

- Terraform can also deploy Kubernetes resources. Point is, Terraform can deploy to many different resources.

- It does this through the terriform registry where it will use plugins and api calls to deploy to different providers.


						IaC with Version control (git)
 

- IAC can be stored in git. This allows you to track changes, roll back commits, and collabarate amongst team members.

- Terraform State file and Terraform lock file keep the IAC stable while teams are working on it. Not sure how yet. 


					Infra Orchestration vs Config Management



			Infra Orchestration					Config Management


- Tools: CloudFormation , Terraform				- Tools: chef , Ansible , puppet
- Arranging the essentials in a particular order		- Consider what runs inside the machine.
- Used for overall deployment of infrastructure			- Configure the infra to run app code.  
- Describes the infrastructre state. (What you want)		- Install software, manage files, ensure services run. 
- Declarative (I want this. Terraform figures out how to do it) - eg: Install Nginx, setup permissions, config firewalls




						The terraform WorkFlow


	Practioner -> Infrastructure as code ---> Plan  ---------------> Run an 'Apply' ----> Deployed on Cloud

	   (Me)		(Writes code)	  (Terraform plan command)     (Apply the IAC plan)





						Tips for using Terraform


- Use the official Terraform Documentation. 
- Terraform registry - Used daily when using terraform and deploying. This includes documentation for AWS provider.
- Testing and Validation - (You don't want to break/delete important live code. So important to test and validate)
- Start with a small MVP (Minimum Viable Product) then iterate. Configure resource you need to deploy then add on to it.
- Implement Dry Software engineering Principle. (Do not repeat yourself. Use modules. Make as dry as possible)





						Terraform State File


- The state file is very important.
- The terraform state file is the blueprint. It is a record of your current existing infrastructure.
- The terraform state file ensures idompotency. Idompotency:
  (Terraform config will always produce the same result). If changes are made to state file config, it doesn't
  completely change everything, it just applies particular change.

When you run terraform apply, terraform checks your code, what currently exists, the differences (if any)
and if there is no differences, then no changes are made. This is what we call idompotency. Always getting the same
result unless something has actually changed in the code. 

This means that it is safe to re-apply your infrastructure. Reduces risk of recreating things. Keeps infra stable. 
Works well in CI/CD pipelines.

Terraform plan shows ONLY what will change.



						Desired vs Current State


- .tf			> Desired State (Your terraform config. Maybe changes you are trying to implement)
- .tfstate		> Current State (The state file)  


						The Backend

- This is where terraform stores your state file. It can be located on local device or can direct to a shared S3 bucket.




						Terraform Commands:

terraform init		- Sets up work place. (Terraform block/provider block. libaries/aws log in/backend/modules)
terraform plan		- preview changes terraform will make before they happen. See into the future.  
			  Everything shown in plan refers to changes! Symbols: (+ create) (~ update) (- destroy)
terraform apply		- Takes execution plan and applies it to infrastructure.
			  Will generate execution plan and wait for confirmation from you before performing actions.
terraform destroy	- Safely and Efficiently tears down infrastructure managed by particular .tf config.
			  Reads current config and state file to understand what it's managing. Then generates destroy
			  plan. Can specify which sources to destroy. Will also wait for confirmation. 
			  Terraform then updates state file to confirm resources have been destroyed. 
terraform refresh	- updates the state file to match the current real world infrastructure. Ensures in sync. 	





						Terraform Providers

- Just simply a plugin that allows you to interact with cloud platforms and enables terraform to manage cloud resources.

				---------------------------------------------------------------

						Terraform Provider Code Block

Terraform { required_providers { ... } }			>  This is the Terraform Provider block. Example below.


Terraform {
     required_providers {
	aws = {
	  source = "hashicorp/aws"				> The libary of code that knows how to interact with aws
	  version = "5.62.0"
	}
     }
  }

Provider "aws" {
	#Configuration options		>	To login to your aws basically. can use ~/.aws/credentials
  }


				-----------------------------------------------------------------

				

							Resource Block

- Used to define a piece of infrastructure that you want to manage.
- Each resource block corresponds to specific resource type. 


				-----------------------------------------------------------------

						EC2 resource block


resource "aws_instance" "name" {				# Specify which resource and it's name. 
  ami = "xyz" 							# Amazon Machine image. Template for instance
  instance_type = "t2.micro"					# Self Explanatory. 
Tags = {							# A way to label/categorise resources. Not compulsory
Name = "Bugfix"							  But good practice. Tags include: Name, team, owner etc
}
}



				----------------------------------------------------------------




						Terraform Importing


- If a resource already exists in cloud environment but not created with terraform. What do we do? Terraform import.
- Terraform brings existing resources under terraform's management. 


- We use an 'import block' to import instances using the id. 
- Terraform docs guide us on exactly how to do this.
- Very simple... Look code below.
- you can run this directly from the terminal or make a tf file, plan, apply, then delete it once done.
- Oh by the way, you need to manually add the resource into ur actual.tf file so it knows where it's important 'to'. 

				-----------------------------------------------------------------

import {
  to = aws_instance.web
  id = "i-xyz123"
}

				-----------------------------------------------------------------

- Check if the terraform import works by running a terraform plan. Check if everything matches. 






						Local vs Remote Statefiles

Backend : Where and how Terraform stores it's state file. Commonly teams use AWS S3 with DynamoDB for statelocking.
To clarify though! the .tf file can be stored on a shared github repositary but the backend refers to the state file
													   exclusively

Best Practices: 

- Regularly backup the state files
- State locking. Make sure backend ensures state locking to prevent concurrent changes
- Encrypt state files. Appling encryption on state files, especially in remote back end is crucial to protect data.
- Consider version control. Do not commit state files to github repositaries as they may contain sensitive data.
- For terraform configurations though, we can of course use git hub as this allows for team collabaration. 


				---------------------------------------------------------------

terraform {
  backend "s3" {
    bucket         = "my-terraform-state-bucket"
    key            = "dev/network/terraform.tfstate"
    region         = "us-east-1"
    dynamodb_table = "terraform-locks"
    encrypt        = true
  }
}

This backend code is specified in the terraform block (that you initially terraform init)
Note that you are telling terraform where to state the state file. So the s3 bucket should already exist... 
You can deploy the s3 bucket manually, and it doesn't even need to be imported as it's not part of ur infra. 
				------------------------------------------------------------------

							Local Statefile


- Default. Terraform stores your statefile locally on your machine in your project directory.
- Easy to set up. No additional config required on where to store your state file.
- Good for single user projects.



							Remote Statefile


- When working in a team/larger projects we need to use a Remote Statefile. 
- Remote statefiles store the state in a central remote location (like an s3 bucket)
- Multiple team members can access and update the state. 
- Automatic locking: Many remote backends (like terraform cloud or s3 bucket + DynamoDB) offer state locking.
- State locking prevents people working on the state file at the same time. 
- Remote backends can automatically back up state file and provide encryption.





							Variables

- Allows you to write cleaner, more dynamic code allowing you to manage different environments and setups. 
- A way to paramaterise your configuration. Instead of hard coding into config files, can define values as variables
- Makes your code more 'dry'. (Do not repeat yourself)
- Variables are written in a seperate variables.tf file




						Declaring Input Variables

- Define Input variables to recieve value from user/command line/ variable files


				---------------------------------------------------------------

variable "instance_type" {
  type = string				> Looking for string input
  default = t3.micro			> The actual thing we want when we call on the variable.
)

				--------------------------------------------------------------


Now variables can be specified in a 'variables.tf' file and tf will read them automatically while planning/applying.

This is fine as it honestly. 

However, if you reall want, best practice is actually using terraform.tfvars along with your variables.tf file.

--------------------------------------------------------------------------------------------------------------
						terraform.tfvars
instance_type = "t3.micro"


--------------------------------------------------------------------------------------------------------------




						Local Variables


Just used to save time. If values do not need to be configured externally, theres no reason to use input variables. 
Instead we can just set local variables using a locals {} block to stay efficient/dry while configuring our .tf file.

The preferred way to do it is to define multiple local variables all within a single locals {} block. Example:


		-------------------------------------------------------------------------- 


locals {
  env           = "dev"
  instance_name = "web-${local.env}"
  region        = "us-east-1"
  common_tags = {
    Environment = local.env
    Owner       = "DevOps"
  }
}


		---------------------------------------------------------------------------





						Output Variables


- Used to display values after your entire terraform apply has run and been completed. 
- This can be id's, ip's or other important information.
- Useful for passing info to other configurations, automation tools or displaying them for your own reference.
- To define output variable, we use an output block. 
- In the output block u specify name of output, description, and value you want to output. 



		----------------------------------------------------------------------------	


output "instance_id" {
  description = "The Id of the EC2 instance"
  value = (resource.name.id goes here)			> make sure to use .id. Gives you a useful list too. 
}


		----------------------------------------------------------------------------


- Use descriptive names so you know exactly what you are outputting.
- Always include a description for variables so it's easily understandable. 
- Use outputs to expose critical information for automation/manual intervention/chaining tf configs together. 
- Be causious when outputting sensitive information... 




							Varibale Hierarchy


- How terraform reads and prioritises variables

1. Command line flags
2. TF_VAR Environment Variables 			> These are actual env variables set on your system (export)
3. .tfvars Files					> Will override the default values
4. Default Values					> Set in input variables






						Types of Variables



There are simple variables as shown above and complex variables (which i've already investigated)

Complex  variables involve multiple values all within the same variable. we utilise {} within the variable block



---------------------------------------------------------------------------------------------------------------

variable "example_list" {

type = list(string)
default = ["one","two" ...]

}


variable "example_map" {

type = map(string)
default = {
foo = "bar"
baz = "qux"

}
}


variable "ec2_config" {
  type = object({
    ami           = string
    instance_type = string
    subnet_id     = string
    key_name      = string
    tags          = map(string)
  })

  default = {
    ami           = "ami-0c55b159cbfafe1f0"
    instance_type = "t3.micro"
    subnet_id     = "subnet-abc123"
    key_name      = "my-key"
    tags = {
      Name  = "example-instance"
      Owner = "DevOps"
    }
  }
}

--------------------------------------------------------------------------------------------------------------




							MODULES


Modules are like reusable packages stored in subdirectories, each with their own input variables and configuration logic
Instead of rewriting the same setup, we can call a module from our main .tf file, passing in values as needed.
We can also override default variable values when calling a module — and those overrides will take precedence.
This makes modules ideal for organizing, reusing, and scaling Terraform code across different environments or projects.


- Improves re-usability
- Dryness
- Organisation
- Consistency
- Allow cross team/project collabaration
- Package and re-use infrastructure code.
- Perhaps use a module to enforce consistent SG's

						What makes a good module?

- flexible
- well documented
- easy to use
- Simplicity
- Output values
- Avoid hardcoding values that might change between environments like instance types, regions etc. Pass in as variables.
- Modules need to be focused on single responsibility.


- Need to run a terraform init in order to initialize the modules. 
--------------------------------------------------------------------------------------------------------------------
						How to call a module:

module "web_server" {
  source        = "./modules/ec2_instance"			> Path to module
  ami           = "ami-0c55b159cbfafe1f0"
  instance_type = "t3.micro"
  tags = {
    Name  = "example-web"
    Owner = "DevOps"
  }
}



------------------------------------------------------------------------------------------------------------------ 




						Advanced Terraform Topics



							Local Stack

LocalStack is a tool that lets you run a local version of AWS services on your own machine — without using a real AWS 
account.

Allows you to: Develop and test terraform, cloud apps, and automate scripts locally - WITH ZERO COST.

It's basically an emulation tool so you can practice and make sure your terraform is correct before doing anything. 


							How to make a Local Stack

- First of all, a local stack is ran as a container. There is a public image which we can call and run. Here is how:

- We run it using docker compose. 

--------------------------------------------------------------------------------------------------------------------

v-ersion: "3.8"

se--rvices:

  localstack:

    container_name: "${LOCALSTACK_DOCKER_NAME-localstack_main}"

    image: localstack/localstack:2.3.2

    ports:

      - "4566:4566"            # LocalStack Gateway

      - "4510-4559:4510-4559"  # external services port range


--------------------------------------------------------------------------------------------------------------------

To make a local stack, you need to make sure to define the following endpoint in your terraform providers init code.

required providers {
  aws = {
    source = "hashicorp/aws"
    version = "~> 4.0"
  }
}

required_versions = ">= 1.0"
}

provider "aws" {

access_key	= "test"
secret_key	= "test"
region 		= "us-east-1"
skip_credentials_validation = true
skip_requesting_account_id  = true

endpoints {

ec2 = "http://localhost:4566"			> This is the important part. It is saying, when using ec2 resource, 
	  }					  direct the request to port 4566  (where the container is listening)
}


--------------------------------------------------------------------------------------------------------------------
						





						THE ABSOLUTE FUNDEMENTALS END HERE
	





							The Count argument


- Lets you spin up multiple identical resources (like instances) all within the same resource block. 
- you just pass count in as an argument in the resource block. Very simple. Look below.

--------------------------------------------------------------------------------------------------------------------

resource "aws_instance" "example" {
  count         = 3
  ami           = "ami-044415bb13eee2391" 
  instance_type = "t2.micro"


--------------------------------------------------------------------------------------------------------------------
??? from here until ???END lines may have been inserted/deleted

							for_each loops


- great for spinning up multiple resources of the same type but with different configurations 

----------------------------------------------------------------------------------------------------------------

provider "aws" {
  region = "us-east-1"
}

locals {
  ec2_instances = {
    dev     = "t2.micro"
    staging = "t3.micro"
    prod    = "t3.small"
  }
}

resource "aws_instance" "ec2" {
  for_each = local.ec2_instances		# loops over the map of values

  ami           = "ami-044415bb13eee2391" 	
  instance_type = each.value			# Defines the instance type for that region

  tags = {
    Name = "${each.key}-instance"
  }
}

----------------------------------------------------------------------------------------------------------------
						
							MASTER UP TO HERE






							rest i can take my time on.



							coalesce function

- Takes list of values and returns the first one which isn't null or an empty string ("")	
- basically, if no string is passed through as argument and default is not set in variable, coalese will do it's thing.
- set a generic value to use as a backup default. 
- can combine with the lookup function to also search for a value. (look into this more if/when needed)

example: name = coalesce(var.user_defined_name, "generic-name")



							try function:

- In Terraform, the try function evaluates each argument in order and returns the first one that doesn’t produce an 
 error. It’s useful for setting fallback values when dealing with optional or error-prone expressions.
- Once again, look into this further if required to.



							merge function:

- To combine multiple map's into 1. If you have default tags, always want resources + env tags in 1. 
- Don't fully understand this tbh, but once again, look into when needed.  



							Conditionals

- Allow you to control the flow of terraform code based on certain conditions. 
- ALlow you to exectue blocks depending on a value of a variable/resource attribute. 
- Ok this one is important. Simple too. Look below

----------------------------------------------------------------------------------------------------------------------

Example 1: Instance type depends on the string value in environment variable

variable "environment" {
type = string
default = "dev"								# Can also be set to prod. So dev/prod
}

resource "aws_instance" "conditional_instance" {
ami = "ami-test"

instance_type = var.envrionment == "prod" ? "t3.large" : "t2.micro"	# based on value of environment var.
									# if prod then use t3.large, otherwise t2.micro

----------------------------------------------------------------------------------------------------------------------

Example 2: Wether or not to create an elastic ip, based on our variables. 


variable "environment" {
type = string
default = "dev"                                                         
}

resource "aws_instance" "main" {
ami = xyz
instance_type = t2.micro
}


resource "aws_eip" "optional_eip" {

count = var.environment == "prod" ? 1:0				# If env = prod create an elastic IP otherwise do not.

instance = aws_instance.main.id					# where to add the elastic ip.
}

----------------------------------------------------------------------------------------------------------------------
There is more to know about conditionals for dynamic configurations but I will cover it later.



						Concatenation

- A simple way to join 2 lists into 1 big list. 
- Produces a single list. 

locals {
list_one = ["dev", "test"]
list_two = ["prod", "staging"]
merged_list = concat(local.list_one, local.list_two)		# concat command used here to join the lists. 
}



------------------------------------------------------------------------------------------------------------------

							File Function

Super useful tool for injecting entire config files/scripts into resource like user data without hardcoding into tf. 


1. First of all, in your variables, you make a variable which points towards the script. 
2. call  the variable in your resource block.
---------------------------------------------------------------------------------------------------------------------

variable "userdata_file" {

type = string
default = "${path.module}/user_data.sh			# The path to the script
}

resource "aws_instance" "file_example" {
ami = "ami-test"
instance_type = "t2.micro"

user_Data = file (var.userdata_file)

}
---------------------------------------------------------------------------------------------------------------------

							Lowercase/Uppercasing

quick command used to make strings entirely lowercase or entirely uppercase. Just convenience. 
 




						Can Function for conditional logic


- If we are unsure if .tf code will work, we can use a can function to check.
- If there are any mistakes in var string values, json format unreadable, can will give us a nice msg.
- can even configure can to stop the tf run if there is a code failure. 


------------------------------------------------------------------------------------------------------------------- 

variable "possible_json" {
type = string
# default = " xyz "		# could be invalid
}


locals {
decode_ok  = can(jsondecode(var.possible_json))
final_value = local.decode_ok ? "Valid JSON!" : "Oops, invalid JSON, falling back."
}

-------------------------------------------------------------------------------------------------------------------

				There is more knowledge that I will not cover at this current moment
